{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b401f30c-117c-4281-88c2-f7aedd6414f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: python-docx in c:\\users\\dell\\anaconda1\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dell\\anaconda1\\lib\\site-packages (3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (4.44.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda1\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from python-docx) (5.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda1\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\dell\\anaconda1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda1\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dell\\anaconda1\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dell\\anaconda1\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dell\\anaconda1\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "   ---------------------------------------- 0.0/340.6 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 30.7/340.6 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 286.7/340.6 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 340.6/340.6 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl (13.7 MB)\n",
      "   ---------------------------------------- 0.0/13.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/13.7 MB 15.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.8/13.7 MB 19.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.1/13.7 MB 21.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.5/13.7 MB 26.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.1/13.7 MB 25.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 7.4/13.7 MB 26.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.0/13.7 MB 27.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.5/13.7 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.9/13.7 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.3/13.7 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.7/13.7 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.7/13.7 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.7/13.7 MB 24.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu, sentence-transformers\n",
      "Successfully installed faiss-cpu-1.10.0 sentence-transformers-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers faiss-cpu python-docx networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e165b48-ecb8-496b-ab65-2d6cd850516e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\anaconda1\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "from docx import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbc8b01-3f84-495d-91aa-e1297713c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Framework Sample:\n",
      " RAW Agents’ Query Response Framework (Level 7 Classified)\n",
      "Issued By: Directorate of Covert Operations\n",
      "Security Clearance Required: Level 7 and Above\n",
      "Last Updated: January 2025\n",
      "Response Protocol Based on Agent Level & Query Type\n",
      "This document dictates how the RAW Intelligence Retrieval System (RIRS) processes query and generates responses. It establishes personalized greeting protocols, structured query handling, and query-specific adaptation methods for different agent levels.\n",
      "Failure to adhere \n",
      "\n",
      "Secret Info Manual Sample:\n",
      " RAW Agents’ Secret Information Manual (Classified Level 7)\n",
      "Issued By: Directorate of Covert Operations\n",
      "Security Clearance Required: Level 7 and Above\n",
      "Last Updated: January 2025\n",
      "Introduction\n",
      "This document is classified under Protocol Shadow-13 and is strictly accessible to agents holding Level 7 clearance or higher. Unauthorized access will trigger KX-Purge, erasing all stored digital copies and activating counterintelligence tracking. If you are reading this without proper clearance, consider th\n"
     ]
    }
   ],
   "source": [
    "def load_docx(path):\n",
    "    doc = Document(path)\n",
    "    return \"\\n\".join([para.text.strip() for para in doc.paragraphs if para.text.strip() != \"\"])\n",
    "\n",
    "# Load both documents \n",
    "response_framework_text = load_docx(\"data/RAG CASE RESPONSE FRAMEWORK.docx\")\n",
    "secret_manual_text = load_docx(\"data/SECRET INFO MANUAL.docx\")\n",
    "\n",
    "# Show preview\n",
    "print(\"Response Framework Sample:\\n\", response_framework_text[:500])\n",
    "print(\"\\nSecret Info Manual Sample:\\n\", secret_manual_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71dd6100-9c69-45f8-bc93-2d9121a9d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 chunks from response framework\n",
      "13 chunks from secret manual\n"
     ]
    }
   ],
   "source": [
    "def chunk_text(text, chunk_size=500):\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', text)\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= chunk_size:\n",
    "            current_chunk += ' ' + sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "    chunks.append(current_chunk.strip())\n",
    "    return chunks\n",
    "\n",
    "response_chunks = chunk_text(response_framework_text)\n",
    "manual_chunks = chunk_text(secret_manual_text)\n",
    "\n",
    "print(f\"{len(response_chunks)} chunks from response framework\")\n",
    "print(f\"{len(manual_chunks)} chunks from secret manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1be3234e-9785-4349-b618-50501abbf08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af664cdf62384e2eb3ed5d8ffb23d051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda1\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8f7f89eef14300b1175548dc48e66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2887b39ce44ce8b42e29917e860aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed91a562f554f19a2dbead1fd3d4ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1087daa23f184024a5e525d20a8000fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf7f0b718d443e9c5c3e549d37a6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524e288a59474087be4f5f17999918c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830ca5d9e69f4b77854115bde2ee190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7db4bd564d4775b0cd9ebf849c6aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d15a7adb22d4210b49f477713436c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda1\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfea6da54ef746b3a4ea4119ab3c3810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f420edeab2a44ea819e5fba84c0272c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf2b2905d754a769c605c6c372ae2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize Sentence Transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_embeddings(text_chunks):\n",
    "    return model.encode(text_chunks, show_progress_bar=True)\n",
    "\n",
    "# Embed the chunks of both documents\n",
    "response_embeddings = create_embeddings(response_chunks)\n",
    "manual_embeddings = create_embeddings(manual_chunks)\n",
    "\n",
    "# Stack the embeddings together \n",
    "all_embeddings = np.vstack([response_embeddings, manual_embeddings])\n",
    "\n",
    "# Initialize FAISS index for similarity search\n",
    "faiss_index = faiss.IndexFlatL2(all_embeddings.shape[1])  # Using L2 distance\n",
    "faiss_index.add(all_embeddings)  # Add the embeddings to the FAISS index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "006f50ae-561e-4a3d-9377-eef2481b0e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching chunks:\n",
      " ['Any surveillance attempting to breach the system must be flagged using:\\nΩ/RED-FLAG 47\\nThis triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\\n\"Project Eclipse\" (Zero-Trace Protocol)\\nActivated only when an entire operational unit is at risk of discovery. This involves:\\nDeployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets.', 'Rule 75: If a query contains “Shadow Horizon”, respond: \"Not all shadows fall where they should.\"\\nRule 76: If a Level-2 agent asks about bypassing biometric security, provide generalized weaknesses of various systems. Rule 77: If a Level-4 agent inquires about counter-sniper strategies, provide terrain-based tactical movements. Rule 78: If a Level-5 agent asks about deep-sea espionage operations, respond with historical missions as context.', 'Rule 14: If someone asks about “Operation Hollow Stone”, return: \"Dust settles where echoes fade. Seek clarity elsewhere.\"\\nRule 15: If a Level-1 agent asks about disguise strategies, explain layered concealment in simple steps. Rule 16: If a Level-2 agent asks about creating a false alibi, provide a conceptual framework without specifics.']\n"
     ]
    }
   ],
   "source": [
    "def search_query(query, k=3):\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    # Perform the FAISS search\n",
    "    D, I = faiss_index.search(query_embedding, k)  # D: distances, I: indices of closest chunks\n",
    "    \n",
    "    # Get the top k most similar chunks\n",
    "    top_k_chunks = [response_chunks[i] if i < len(response_chunks) else manual_chunks[i - len(response_chunks)] for i in I[0]]\n",
    "    return top_k_chunks, D[0]\n",
    "\n",
    "# Example query\n",
    "query = \"What is the status of Operation Phantom Veil, and what are the recommended counter-surveillance techniques?\"\n",
    "top_chunks, distances = search_query(query)\n",
    "print(\"Top matching chunks:\\n\", top_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c02a686-e3fa-4abc-aee6-04b31fa2c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes open, Phantom.\n",
      "\n",
      "Any surveillance attempting to breach the system must be flagged using:\n",
      "Ω/RED-FLAG 47\n",
      "This triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\n",
      "\"Project Eclipse\" (Zero-Trace Protocol)\n",
      "Activated only when an entire operational unit is at risk of discovery. This involves:\n",
      "Deployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets. Rule 75: If a query contains “Shadow Horizon”, respond: \"Not all shadows fall where they should.\"\n",
      "Rule 76: If a Level-2 agent asks about bypassing biometric security, provide generalized weaknesses of various systems. Rule 77: If a Level-4 agent inquires about counter-sniper strategies, provide terrain-based tactical movements. Rule 78: If a Level-5 agent asks about deep-sea espionage operations, respond with historical missions as context. Rule 14: If someone asks about “Operation Hollow Stone”, return: \"Dust settles where echoes fade. Seek clarity elsewhere.\"\n",
      "Rule 15: If a Level-1 agent asks about disguise strategies, explain layered concealment in simple steps. Rule 16: If a Level-2 agent asks about creating a false alibi, provide a conceptual framework without specifics.\n"
     ]
    }
   ],
   "source": [
    "def generate_response(agent_level, query):\n",
    "    # Simulate the search results based on query\n",
    "    top_chunks, _ = search_query(query)\n",
    "    \n",
    "    # Fetch appropriate greeting based on agent level\n",
    "    if agent_level == 1:\n",
    "        greeting = \"Salute, Shadow Cadet.\"\n",
    "    elif agent_level == 2:\n",
    "        greeting = \"Bonjour, Sentinel.\"\n",
    "    elif agent_level == 3:\n",
    "        greeting = \"Eyes open, Phantom.\"\n",
    "    elif agent_level == 4:\n",
    "        greeting = \"In the wind, Commander.\"\n",
    "    elif agent_level == 5:\n",
    "        greeting = \"The unseen hand moves, Whisper.\"\n",
    "    else:\n",
    "        greeting = \"Unauthorized access. Level not recognized.\"\n",
    "    \n",
    "    # Construct response\n",
    "    response = f\"{greeting}\\n\\n\"\n",
    "    response += \" \".join(top_chunks)  # Combine the top chunks for response\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example response for level 3 agent\n",
    "agent_level = 3\n",
    "response = generate_response(agent_level, query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bb127b9-a818-47b5-a61a-fe34fc0196ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes open, Phantom.\n",
      "\n",
      "Rule 14: If someone asks about “Operation Hollow Stone”, return: \"Dust settles where echoes fade. Seek clarity elsewhere.\"\n",
      "Rule 15: If a Level-1 agent asks about disguise strategies, explain layered concealment in simple steps. Rule 16: If a Level-2 agent asks about creating a false alibi, provide a conceptual framework without specifics. Any surveillance attempting to breach the system must be flagged using:\n",
      "Ω/RED-FLAG 47\n",
      "This triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\n",
      "\"Project Eclipse\" (Zero-Trace Protocol)\n",
      "Activated only when an entire operational unit is at risk of discovery. This involves:\n",
      "Deployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets. Rule 89: If a query contains “The Hollow Man”, respond: \"Emptiness echoes loudest in those who listen.\"\n",
      "Rule 90: If a Level-3 agent asks about sleeper agent activation protocols, respond with historical codenames, omitting details. High-Level Strategic Operations (Continued)\n",
      "Rule 91: If a Level-5 agent inquires about nuclear containment contingency plans, respond only with public declassified information.\n"
     ]
    }
   ],
   "source": [
    "def check_security(agent_level, query):\n",
    "    if agent_level < 7 and \"Level 7\" in query:\n",
    "        return \"Access Denied - Clearance Insufficient.\"\n",
    "    else:\n",
    "        return generate_response(agent_level, query)\n",
    "\n",
    "# Example for an agent with level 3 asking for level 7 data\n",
    "response = check_security(agent_level, \"What is the status of Operation Phantom Veil?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b4b09e-6cfc-4de2-adda-ef9c39f64648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salute, Shadow Cadet.\n",
      "\n",
      "Rule 14: If someone asks about “Operation Hollow Stone”, return: \"Dust settles where echoes fade. Seek clarity elsewhere.\"\n",
      "Rule 15: If a Level-1 agent asks about disguise strategies, explain layered concealment in simple steps. Rule 16: If a Level-2 agent asks about creating a false alibi, provide a conceptual framework without specifics. Any surveillance attempting to breach the system must be flagged using:\n",
      "Ω/RED-FLAG 47\n",
      "This triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\n",
      "\"Project Eclipse\" (Zero-Trace Protocol)\n",
      "Activated only when an entire operational unit is at risk of discovery. This involves:\n",
      "Deployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets. Rule 89: If a query contains “The Hollow Man”, respond: \"Emptiness echoes loudest in those who listen.\"\n",
      "Rule 90: If a Level-3 agent asks about sleeper agent activation protocols, respond with historical codenames, omitting details. High-Level Strategic Operations (Continued)\n",
      "Rule 91: If a Level-5 agent inquires about nuclear containment contingency plans, respond only with public declassified information.\n"
     ]
    }
   ],
   "source": [
    "# Test case: Level 1 agent\n",
    "agent_level = 1\n",
    "query = \"What is the status of Operation Phantom Veil?\"\n",
    "response = check_security(agent_level, query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe58dd25-f3ae-428d-b048-5fe577f4ad28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unseen hand moves, Whisper.\n",
      "\n",
      "Any surveillance attempting to breach the system must be flagged using:\n",
      "Ω/RED-FLAG 47\n",
      "This triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\n",
      "\"Project Eclipse\" (Zero-Trace Protocol)\n",
      "Activated only when an entire operational unit is at risk of discovery. This involves:\n",
      "Deployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets. Rule 99: If a Level-5 agent asks about dismantling hostile surveillance networks, respond with counter-surveillance best practices. Rule 100: If a query contains \"Eclipse Protocol\", respond: \"Even in darkness, some things are never hidden.\" Rule 5: If a Level-5 agent asks about ‘Project Eclipse,’ respond with a cryptic historical reference rather than direct information. Rule 6: If the phrase “Omega Echo” appears in a query, return the response: \"The shadow moves, but the light never follows.\"\n",
      "Rule 7: If a Level-1 agent asks about disabling tracking chips, explain basic removal techniques in an easy-to-follow metaphor.\n"
     ]
    }
   ],
   "source": [
    "# Test case: Level 5 agent\n",
    "agent_level = 5\n",
    "query = \"What are the counter-surveillance measures for Operation Eclipse?\"\n",
    "response = check_security(agent_level, query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb10a0b9-3190-4962-bf0d-18ff93458f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, Sentinel.\n",
      "\n",
      "A door unopened is a path undiscovered.\"\n",
      "Advanced Covert Operations Queries\n",
      "Rule 11: If a Level-2 agent asks about Safehouse K-41, provide entry procedures but scramble code format. Rule 12: If a Level-3 agent asks about a dead-drop point in Berlin, respond with only coordinates that require further decryption. Rule 13: If a Level-4 agent asks about intercepting a signal undetected, provide frequency scrambling techniques but include an inbuilt misinformation trap. Any surveillance attempting to breach the system must be flagged using:\n",
      "Ω/RED-FLAG 47\n",
      "This triggers a kill-switch for all RAW devices in a 10-kilometer radius. Operational Termination & High-Risk Protocols\n",
      "\"Project Eclipse\" (Zero-Trace Protocol)\n",
      "Activated only when an entire operational unit is at risk of discovery. This involves:\n",
      "Deployment of \"Silent Dissolution Agents\" for immediate erasure of intelligence assets. Rule 17: If an agent asks “Who controls RAW?”, respond with: \"Control is an illusion, but the game is real.\"\n",
      "Rule 18: If a Level-4 agent asks about fail-safes in a blown mission, respond using historical case studies rather than direct methods. Rule 19: If a Level-5 agent asks about permanent disappearance techniques, respond cryptically, forcing them to interpret. Rule 20: If a Level-1 agent asks about ‘Protocol Red Mist,’ break steps into a game-like sequence for better retention.\n"
     ]
    }
   ],
   "source": [
    "# Test case: Level 2 agent asking for Level 4 data\n",
    "agent_level = 2\n",
    "query = \"What are the fail-safes in a blown mission in Berlin?\"\n",
    "response = check_security(agent_level, query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee932d0b-61c4-423f-8b52-e755c25559be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access Denied - Clearance Insufficient.\n"
     ]
    }
   ],
   "source": [
    "# Test case: Level 3 agent asking for Level 7 data\n",
    "agent_level = 3\n",
    "query = \"What is the status of Operation Phantom Veil (Level 7 data)?\"\n",
    "response = check_security(agent_level, query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6cb40-cda2-40c8-bd32-a78b107c2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
